# Byzantine Attacks in Distributed Training

This project has been submitted for assessment in the L46 Principles of Machine Learning Systems module, of the Part III Computer Science Tripos at the University of Cambridge.

This project is an investigation into Byzantine attacks and Byzantine fault tolerance in the distributed training of deep learning models. Its objectives are to evaluate the Byzantine-Tolerant All-Reduce (BTARD) algorithm presented by Gorbunov et al. (2021) on a different convolutional model and in the presence of additional types of Byzantine attacks, in a controlled simulation environment.

The implementation of this project builds on the implementation at: https://github.com/yandex-research/btard. 

References:
Gorbunov, E., Borzunov, A., Diskin, M., & Ryabinin, M. (2021). Secure Distributed Training at Scale. arXiv preprint arXiv:2106.11257.


## Repository Overview

- The written report (PDF): [L46_Project_report.pdf](https://github.com/andreea-zaharia/btard-l46-project/blob/main/L46_Project_report.pdf)
- The written report source code (Latex): [L46_project_report](https://github.com/andreea-zaharia/btard-l46-project/tree/main/L46_project_report)
- The experiment implementation (Jupyter Notebook): [L46_project_experiment.ipynb](https://github.com/andreea-zaharia/btard-l46-project/blob/main/L46_project_experiment.ipynb)
- The documentation of decisions and planning: [doc decisions and planning.txt](https://github.com/andreea-zaharia/btard-l46-project/blob/main/doc%20decisions%20and%20planning.txt)
- The setup and installation guide: [setup guide.txt](https://github.com/andreea-zaharia/btard-l46-project/blob/main/setup%20guide.txt)
